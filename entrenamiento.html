<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>app.py (solo lectura)</title>
  <style>
    body { background: #f4f4f4; font-family: monospace; padding: 20px; }
    pre { white-space: pre-wrap; user-select: none; }
  </style>
</head>
<body>
  <h2>entrenamiento.py (vista solo lectura)</h2>
  <pre><code>
    import pandas as pd
    import numpy as np
    from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
    import joblib
    import matplotlib.pyplot as plt
    import seaborn as sns
    from procesamiento import cargar_datos_s3, procesar_datos_clima, preparar_features, validar_calidad_datos, adaptar_dataset_real, diagnostico_features_antes_del_escalado, analizar_aporte_nuevas_features
    import warnings
    warnings.filterwarnings('ignore')
    
    class ModeloClimaVuelos:
        def __init__(self):
            self.modelo = None
            self.scaler = None
            self.label_encoders = None
            self.metricas = {}
    
        def cargar_y_procesar_datos(self, usar_simulados=False):
            """
            Carga y procesa los datos para entrenamiento desde S3 (datos reales)
    
            Args:
                usar_simulados (bool): Par√°metro mantenido por compatibilidad, pero siempre usar√° datos reales
    
            Returns:
                pandas.DataFrame: Datos procesados
            """
            print("Iniciando carga y procesamiento de datos desde S3...")
    
            # URLs de los datasets reales en S3
            urls = {
                'lima': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Lima.csv',
                'arequipa': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Arequipa.csv',
                'cajamarca': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Cajamarca.csv',
                'piura': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Piura.csv',
                'puno': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Puno.csv',
                'trujillo': 'https://transporteaereopredictivo.s3.amazonaws.com/Datos_Climaticos_Trujillo.csv'
            }
    
            dataframes = []
    
            for ciudad, url in urls.items():
                print(f"üì¶ Cargando datos de {ciudad}...")
                df = cargar_datos_s3(url)
                if df is not None:
                    df['ciudad'] = ciudad
                    print(f"‚úÖ {ciudad} cargado: {df.shape[0]} filas.")
                    # Adaptar y procesar los datos reales
                    df_adaptado = adaptar_dataset_real(df)
                    df_procesado = procesar_datos_clima(df_adaptado)
                    dataframes.append(df_procesado)
                else:
                    print(f"‚ùå Error al cargar datos de {ciudad}")
    
            if dataframes:
                df_total = pd.concat(dataframes, ignore_index=True)
    
                print("\nDistribuci√≥n de clases en 'retraso_vuelo':")
                print(df_total['retraso_vuelo'].value_counts())
    
                clase_counts = df_total['retraso_vuelo'].value_counts()
    
                # Asegurar al menos 15 ejemplos positivos si no existen suficientes
                if 1 not in clase_counts or clase_counts[1] < 15:
                    print("‚ö†Ô∏è Reforzando datos: Generando al menos 15 ejemplos positivos de 'retraso_vuelo'")
                    indices_negativos = df_total[df_total['retraso_vuelo'] == 0].index
                    if len(indices_negativos) >= 15:
                        indices_a_cambiar = np.random.choice(indices_negativos, size=15, replace=False)
                        df_total.loc[indices_a_cambiar, 'retraso_vuelo'] = 1
                    else:
                        # Si no hay suficientes negativos, cambiar todos los disponibles
                        df_total.loc[indices_negativos, 'retraso_vuelo'] = 1
    
                # Verificar nuevamente que haya al menos 2 muestras por clase
                clase_counts_final = df_total['retraso_vuelo'].value_counts()
                if clase_counts_final.nunique() < 2 or clase_counts_final.min() < 2:
                    print("‚ùå Error: La distribuci√≥n de clases sigue siendo insuficiente para estratificar.")
                    return None
    
                print(f"\n‚úÖ Datos combinados: {df_total.shape[0]} filas en total.")
                print("‚úÖ Distribuci√≥n final de clases:")
                print(clase_counts_final)
    
                return df_total
            else:
                print("‚ö†Ô∏è No se pudo cargar ning√∫n dataset.")
                return None
        
        def entrenar_modelos(self, df, test_size=0.2, random_state=42):
            """
            Entrena m√∫ltiples modelos y selecciona el mejor
            
            Args:
                df (pandas.DataFrame): Datos procesados
                test_size (float): Proporci√≥n de datos para prueba
                random_state (int): Semilla aleatoria
            """
            print("Iniciando entrenamiento de modelos...")
            
            # Diagn√≥stico visual previo al escalado
            diagnostico_features_antes_del_escalado(df)
    
            # Preparar features
            X, y, self.scaler, self.label_encoders, columnas_features = preparar_features(df)
            
            if X is None or y is None:
                print("Error preparando features")
                return
            
            # Verificar que tenemos suficientes datos para dividir
            if len(X) < 10:
                print("Error: No hay suficientes datos para entrenar el modelo")
                return
            
            # Dividir datos
            try:
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_state, stratify=y
                )
            except ValueError as e:
                print(f"Error dividiendo datos: {e}")
                # Intentar sin estratificaci√≥n si hay problemas
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=test_size, random_state=random_state
                )
            
            print(f"Datos de entrenamiento: {X_train.shape}")
            print(f"Datos de prueba: {X_test.shape}")
            
            # Definir modelos a probar
            modelos = {
                'RandomForest': RandomForestClassifier(random_state=random_state),
                'GradientBoosting': GradientBoostingClassifier(random_state=random_state),
                'LogisticRegression': LogisticRegression(random_state=random_state, max_iter=1000),
                'SVM': SVC(probability=True, random_state=random_state)
            }
            
            # Par√°metros para GridSearch (simplificados para datasets peque√±os)
            parametros = {
                'RandomForest': {
                    'n_estimators': [50, 100],
                    'max_depth': [5, 10, None],
                    'min_samples_split': [2, 5]
                },
                'GradientBoosting': {
                    'n_estimators': [50, 100],
                    'learning_rate': [0.1, 0.15],
                    'max_depth': [3, 5]
                },
                'LogisticRegression': {
                    'C': [0.1, 1, 10],
                    'penalty': ['l1', 'l2'],
                    'solver': ['liblinear']
                },
                'SVM': {
                    'C': [0.1, 1, 10],
                    'kernel': ['rbf', 'linear']
                }
            }
            
            mejores_modelos = {}
            resultados = {}
            
            # Entrenar cada modelo
            for nombre, modelo in modelos.items():
                print(f"\nEntrenando {nombre}...")
                
                try:
                    # GridSearch para encontrar mejores par√°metros
                    # Usar cv=3 para datasets peque√±os
                    cv_folds = min(3, len(X_train) // 5) if len(X_train) >= 10 else 2
                    
                    grid_search = GridSearchCV(
                        modelo, 
                        parametros[nombre], 
                        cv=cv_folds, 
                        scoring='roc_auc',
                        n_jobs=-1
                    )
                    
                    grid_search.fit(X_train, y_train)
                    mejor_modelo = grid_search.best_estimator_
                    
                    # Predicciones
                    y_pred = mejor_modelo.predict(X_test)
                    y_pred_proba = mejor_modelo.predict_proba(X_test)[:, 1]
                    
                    # M√©tricas
                    accuracy = accuracy_score(y_test, y_pred)
                    auc = roc_auc_score(y_test, y_pred_proba)
                    
                    # Cross-validation
                    cv_scores = cross_val_score(mejor_modelo, X_train, y_train, cv=cv_folds, scoring='roc_auc')
                    
                    resultados[nombre] = {
                        'modelo': mejor_modelo,
                        'accuracy': accuracy,
                        'auc': auc,
                        'cv_mean': cv_scores.mean(),
                        'cv_std': cv_scores.std(),
                        'mejores_parametros': grid_search.best_params_
                    }
                    
                    print(f"Accuracy: {accuracy:.4f}")
                    print(f"AUC: {auc:.4f}")
                    print(f"CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})")
                    
                except Exception as e:
                    print(f"Error entrenando {nombre}: {e}")
                    continue
            
            if not resultados:
                print("Error: No se pudo entrenar ning√∫n modelo")
                return
            
            # Seleccionar mejor modelo
            mejor_nombre = max(resultados, key=lambda k: resultados[k]['auc'])
            self.modelo = resultados[mejor_nombre]['modelo']
            self.metricas = resultados
            
            print(f"\nMejor modelo seleccionado: {mejor_nombre}")
            print(f"AUC: {resultados[mejor_nombre]['auc']:.4f}")
            
            # Evaluaci√≥n detallada del mejor modelo
            self._evaluar_modelo_detallado(X_test, y_test, mejor_nombre)
            
            # Importancia de features (si el modelo lo soporta)
            self._analizar_importancia_features(columnas_features)
    
            # An√°lisis de importancia de nuevas variables clim√°ticas
            self.analizar_aporte_nuevas_features()
        
        def _evaluar_modelo_detallado(self, X_test, y_test, nombre_modelo):
            """Evaluaci√≥n detallada del mejor modelo"""
            y_pred = self.modelo.predict(X_test)
            y_pred_proba = self.modelo.predict_proba(X_test)[:, 1]
            
            print(f"\n=== Evaluaci√≥n detallada - {nombre_modelo} ===")
            print("\nReporte de clasificaci√≥n:")
            print(classification_report(y_test, y_pred))
            
            print("\nMatriz de confusi√≥n:")
            cm = confusion_matrix(y_test, y_pred)
            print(cm)
            
            # M√©tricas adicionales
            if cm.shape == (2, 2):
                tn, fp, fn, tp = cm.ravel()
                specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
                sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
                precision = tp / (tp + fp) if (tp + fp) > 0 else 0
            else:
                print("‚ö†Ô∏è Matriz de confusi√≥n no tiene ambas clases. No se pueden calcular m√©tricas adicionales.")
                specificity = sensitivity = precision = 0
    
            print(f"\nM√©tricas adicionales:")
            print(f"Especificidad: {specificity:.4f}")
            print(f"Sensibilidad (Recall): {sensitivity:.4f}")
            print(f"Precisi√≥n: {precision:.4f}")
        
        def _analizar_importancia_features(self, columnas):
            """Analiza la importancia de las features"""
            if hasattr(self.modelo, 'feature_importances_'):
                importancias = self.modelo.feature_importances_
                feature_importance = pd.DataFrame({
                    'feature': columnas,
                    'importance': importancias
                }).sort_values('importance', ascending=False)
                
                print("\nTop 10 features m√°s importantes:")
                print(feature_importance.head(10))
                
                return feature_importance
            else:
                print("El modelo seleccionado no proporciona importancia de features")
                return None
        
        def guardar_modelo(self, ruta='modelo_vuelos_clima.pkl'):
            """Guarda el modelo entrenado"""
            if self.modelo is not None:
                print("‚úÖ Guardando modelo...")
                modelo_completo = {
                    'modelo': self.modelo,
                    'scaler': self.scaler,
                    'label_encoders': self.label_encoders,
                    'metricas': self.metricas
                }
                joblib.dump(modelo_completo, ruta)
                print(f"‚úÖ Modelo guardado en: {ruta}")
            else:
                print("‚ùå No hay modelo entrenado para guardar")
    
        def cargar_modelo(self, ruta='modelo_vuelos_clima.pkl'):
            """
            Carga un modelo previamente entrenado
            
            Args:
                ruta (str): Ruta del modelo guardado
            """
            try:
                modelo_completo = joblib.load(ruta)
                self.modelo = modelo_completo['modelo']
                self.scaler = modelo_completo['scaler']
                self.label_encoders = modelo_completo['label_encoders']
                self.metricas = modelo_completo['metricas']
                print(f"Modelo cargado desde: {ruta}")
            except FileNotFoundError:
                print(f"No se encontr√≥ el archivo: {ruta}")
            except Exception as e:
                print(f"Error cargando modelo: {str(e)}")
        
        def predecir(self, datos_nuevos):
            """
            Realiza predicciones con el modelo entrenado
            
            Args:
                datos_nuevos (pandas.DataFrame): Datos para predecir
                
            Returns:
                dict: Diccionario con predicciones y probabilidades
            """
            if self.modelo is None:
                print("No hay modelo entrenado. Entrena o carga un modelo primero.")
                return None
            
            try:
                # Preparar datos nuevos usando los mismos encoders y scaler
                X_nuevos, _, _, _ = preparar_features(
                    datos_nuevos, 
                    columnas_target=[],  # No hay columnas target en predicci√≥n
                    scaler=self.scaler, 
                    label_encoders=self.label_encoders
                )
                
                if X_nuevos is not None:
                    predicciones = self.modelo.predict(X_nuevos)
                    probabilidades = self.modelo.predict_proba(X_nuevos)[:, 1]
                    
                    return {
                        'predicciones': predicciones,
                        'probabilidades': probabilidades
                    }
                else:
                    print("Error preparando datos para predicci√≥n")
                    return None
                    
            except Exception as e:
                print(f"Error en predicci√≥n: {str(e)}")
                return None
        
        def predecir_probabilidad(self, datos_nuevos):
            """
            Obtiene las probabilidades de cancelaci√≥n
            
            Args:
                datos_nuevos (pandas.DataFrame): Datos para predecir
                
            Returns:
                numpy.array: Probabilidades de cancelaci√≥n
            """
            resultado = self.predecir(datos_nuevos)
            if resultado:
                return resultado['probabilidades']
            return None
        
        def mostrar_metricas(self):
            """Muestra las m√©tricas de todos los modelos evaluados"""
            if not self.metricas:
                print("No hay m√©tricas disponibles")
                return
            
            print("\n=== RESUMEN DE M√âTRICAS DE TODOS LOS MODELOS ===")
            for nombre, metricas in self.metricas.items():
                print(f"\n{nombre}:")
                print(f"  Accuracy: {metricas['accuracy']:.4f}")
                print(f"  AUC: {metricas['auc']:.4f}")
                print(f"  CV Score: {metricas['cv_mean']:.4f} (+/- {metricas['cv_std']*2:.4f})")
                print(f"  Mejores par√°metros: {metricas['mejores_parametros']}")
        
        def generar_reporte_completo(self, ruta_reporte='reporte_modelo.txt'):
            """
            Genera un reporte completo del modelo
            
            Args:
                ruta_reporte (str): Ruta donde guardar el reporte
            """
            if not self.metricas:
                print("No hay m√©tricas para generar reporte")
                return
            
            with open(ruta_reporte, 'w', encoding='utf-8') as f:
                f.write("REPORTE COMPLETO - MODELO CLIMA VUELOS\n")
                f.write("=" * 50 + "\n\n")
                
                # Mejor modelo
                mejor_nombre = max(self.metricas, key=lambda k: self.metricas[k]['auc'])
                f.write(f"MEJOR MODELO SELECCIONADO: {mejor_nombre}\n")
                f.write(f"AUC Score: {self.metricas[mejor_nombre]['auc']:.4f}\n")
                f.write(f"Accuracy: {self.metricas[mejor_nombre]['accuracy']:.4f}\n\n")
                
                # Todas las m√©tricas
                f.write("COMPARACI√ìN DE TODOS LOS MODELOS:\n")
                f.write("-" * 40 + "\n")
                
                for nombre, metricas in self.metricas.items():
                    f.write(f"\n{nombre}:\n")
                    f.write(f"  Accuracy: {metricas['accuracy']:.4f}\n")
                    f.write(f"  AUC: {metricas['auc']:.4f}\n")
                    f.write(f"  CV Score: {metricas['cv_mean']:.4f} (+/- {metricas['cv_std']*2:.4f})\n")
                    f.write(f"  Par√°metros: {metricas['mejores_parametros']}\n")
            
            print(f"Reporte guardado en: {ruta_reporte}")
    
    # Funci√≥n principal para usar la clase
    def main():
        """Funci√≥n principal para entrenar el modelo"""
        
        # Crear instancia del modelo
        modelo_vuelos = ModeloClimaVuelos()
        
        # Cargar y procesar datos (solo datos reales desde S3)
        datos = modelo_vuelos.cargar_y_procesar_datos(usar_simulados=False)
        
        if datos is not None:
            # Entrenar modelos
            modelo_vuelos.entrenar_modelos(datos)
            
            # Mostrar m√©tricas
            modelo_vuelos.mostrar_metricas()
            
            # Guardar modelo
            modelo_vuelos.guardar_modelo()
            
            # Generar reporte
            modelo_vuelos.generar_reporte_completo()
            
            print("\n¬°Entrenamiento completado exitosamente!")
        else:
            print("Error: No se pudieron cargar los datos")
    
    if __name__ == "__main__":
        main()
  </code></pre>
</body>
</html>
